{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "\n",
    "from RFML_localization.core import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFML_localization\n",
    "\n",
    "> Focus on repository is the location of uncooperative wireless emitters in an indoor environment.  The challenge is that an indoor environment results in dynamic, random propagation of wireless signals.  An approach is to create a RF fingerprint or map of the environment using different RF measurements techniques. Relevant measurements techniques generate a range of data from IQ samples to correlation curves to time-delay estimates (TDE's) for  TDOA; multiple power readings for RSS; and multiple angle of arrival readings for AoA.  The theoretical performance bounds are generated, via CRLB, of empirically measured and derived channel limitations that exists in literature.  From same literature, a simulation model is created that generates the specified random RF channel environment. From these foundations, regression models, that learn from the data in predicting the location of detected emitters, can be tested and validated; some of which are presented here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Github (using notebooks)\n",
    "    - git clone\n",
    "    - cd rfml_localization\n",
    "    - jupyter lab \n",
    "2. Github (using pure python lib)\n",
    "    - git clone\n",
    "    - cd rfml_localization/RFML_localization\n",
    "    - python\n",
    "        - import RFML_localization\n",
    "3. pip install\n",
    "    - **not done yet** ~~`pip install RFML_localization`~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary purpose of package is to use available optimization techniques with RF fingerprinting for indoor localization.  The package is written to enable the leveraging of [Sci-Kit Learn](https://scikit-learn.org/).  In addition, it enables the use of GLMnet - (see [Glmnet Vignette](https://glmnet-python.readthedocs.io/en/latest/glmnet_vignette.html)). This package includes a simulation mode, `RFsimulation`, to generate a set of locations and associated synthetic measurements.  For optimization, the focus is on kernilzing data, see `HFF_k_matrix`, and then pairing with regression models ([Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html), [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html), [MLPregressor](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html), etc) within SKLearn or the Glmnet model.  The kernelized measurement parameters are tuned along with chosen model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Optimization\n",
    "To use, first step is create an `RFchannel instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import RFML_localization.RFsimulation as RFsim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#generate channel scenario using default channel parameters\n",
    "RFchannel_scenario1 = RFsim.RFchannel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object's channel parameters are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxSpreadT, PoissonInvLambda, Poissoninvlambda, PoissonGamma, Poissongamma, PathLossN, Xsigma, Wavelength, AoAsigma, "
     ]
    }
   ],
   "source": [
    "#print out object variables\n",
    "for x in RFchannel_scenario1.__dict__:\n",
    "    print(x,end=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After setting up the environment, create a sensor setup (Tx and Rx locations) and make 1000 observations of a Tx at random locations.  As methods are run on the object, additional variable are added.  This allows inspection of user-specified parameters and even methods run on object.  They are listed below.  Compare to previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxSpreadT, PoissonInvLambda, Poissoninvlambda, PoissonGamma, Poissongamma, PathLossN, Xsigma, Wavelength, AoAsigma, n_runs, n_rx, areaWL, sensor_locs, rxtx_flag, grid_flag, seed_loc, rxtx_locs, ch_delay_flag, tdoa_flag, seed_tdoa, rxx_delay, ch_gain_flag, drss_flag, seed_rss, rxx_rssi, ch_angle_flag, daoa_flag, seed_aoa, rxx_aoa, seed_Xmodel, X_model, "
     ]
    }
   ],
   "source": [
    "#from channel scenario, generate locations for Tx and Rx and set of measurements\n",
    "RFchannel_scenario1.generate_RxTxlocations(n_rx=6, n_runs=10000, rxtx_flag=3)\n",
    "#generate set of measurements\n",
    "RFchannel_scenario1.generate_Xmodel()\n",
    "#print out object variables\n",
    "for x in RFchannel_scenario1.__dict__:\n",
    "    print(x,end=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that a set of measurements are created, split for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shapes of training data:\n",
      " (6700, 27) (6700, 2)\n"
     ]
    }
   ],
   "source": [
    "#take object's set of measurements and assign to X,y\n",
    "X=RFchannel_scenario1.X_model  #measurements/observations\n",
    "y=RFchannel_scenario1.rxtx_locs[:,0,:].transpose()  #location of  Tx\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "print(\" Shapes of training data:\\n\",X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SKLearn Regressor\n",
    "\n",
    "After generating locations, import SKLearn models for regression.  Use the SKLearn-based kernel trick function, `sklearn_kt_regressor`, which wraps a specified SKLearn model and kernelized matrix into a single interface to enable use of SKLearn hyper-tuning tools.  The `sklearn_kt_regressor` inherits all the basic functionality of standard SKLearn model API.  The following sets up model, sets parameters, fits the model, and then predicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel_s0': 1.13e-06, 'kernel_s1': 0.00207, 'kernel_s2': 10.0, 'n_kernels': 3, 'n_meas_array': array([15,  6,  6]), 'skl_kernel': 'rbf', 'skl_model__alpha': 1.83e-06, 'skl_model__copy_X': True, 'skl_model__fit_intercept': True, 'skl_model__max_iter': None, 'skl_model__normalize': False, 'skl_model__random_state': None, 'skl_model__solver': 'auto', 'skl_model__tol': 0.001, 'skl_model': Ridge(alpha=1.83e-06)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "#based on knowledge of measurement, can derive from class instance rather than manually entering\n",
    "#variables (shape[1] of rxx_delay, rxx_rss, rxx_aoa, i.e., RFchannel_scenario1.rxx_delay.shape[1])\n",
    "num_meas_array = np.array([15,6,6]) \n",
    "#tuning parameter for each kernel\n",
    "kernel_s0, kernel_s1, kernel_s2 = np.array([1.13e-06, 2.07e-03, 10])\n",
    "\n",
    "#set up the model\n",
    "skl_kt_model = sklearn_kt_regressor(skl_model = Ridge(alpha=.01), skl_kernel = 'rbf', \n",
    "                                    n_kernels = 3, kernel_s0 = kernel_s0, kernel_s1 = kernel_s1, \n",
    "                                    kernel_s2 = kernel_s2, n_meas_array=num_meas_array)\n",
    "\n",
    "#set/get model parameters - showing methods inherited from SKLearn\n",
    "#assign a model parameter\n",
    "skl_kt_model.set_params(skl_model__alpha = 1.83e-06)\n",
    "#display model params\n",
    "print(skl_kt_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn_kt_regressor(kernel_s0=1.13e-06, kernel_s1=0.00207, kernel_s2=10.0,\n",
       "                     n_kernels=3, n_meas_array=array([15,  6,  6]),\n",
       "                     skl_kernel='rbf', skl_model=Ridge(alpha=1.83e-06))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model\n",
    "skl_kt_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error for (x,y) location estimation is   9.9 meters\n"
     ]
    }
   ],
   "source": [
    "#predict the model\n",
    "y_pred = skl_kt_model.predict(X_test)\n",
    "#error measurement\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "print('Average error for (x,y) location estimation is {:5.2g} meters'.format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GLMnet Regressor \n",
    "The GLMnet regressor, `glmnet_kt_regressor`, is defined in such a way to follow the SKLearn API -- advantageous in leveraging large body of tools.  Below steps through setting up a model, fitting, and predicting.  Using same data and kernel settings as `skl_kt_regressor` example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "glmnet_kt_regressor(glm_alpha=0,\n",
       "                    glmnet_args={'family': 'mgaussian', 'standardize': False},\n",
       "                    kernel_s0=1.13e-06, kernel_s1=0.00207, kernel_s2=10.0,\n",
       "                    lambdau=array([0.001]), n_kernels=3,\n",
       "                    n_meas_array=array([15,  6,  6]), skl_kernel='rbf')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use same training and testing set\n",
    "num_meas_array = np.array([15,6,6]) \n",
    "kernel_s0, kernel_s1, kernel_s2 = np.array([1.13e-06, 2.07e-03, 10])\n",
    "#glmnet_args={'family': 'mgaussian', 'standardize': False}\n",
    "glmnet_args=dict(family= 'mgaussian', standardize= False)\n",
    "\n",
    "#set up the model\n",
    "glm_kt_model = glmnet_kt_regressor(glm_alpha=0, lambdau=1e-3, skl_kernel='rbf', n_kernels=3,\n",
    "                 kernel_s0 = kernel_s0, kernel_s1 = kernel_s1, kernel_s2 = kernel_s2,\n",
    "                 n_meas_array=num_meas_array, glmnet_args=glmnet_args)\n",
    "\n",
    "#fit the model\n",
    "glm_kt_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error for (x,y) location estimation is    23 meters\n"
     ]
    }
   ],
   "source": [
    "#predict the model\n",
    "y_pred = glm_kt_model.predict(X_test)\n",
    "#error measurement\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "print('Average error for (x,y) location estimation is {:5.2g} meters'.format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization\n",
    "\n",
    "Generally speaking, model and kernel parameters need to be tuned. Building on previous example, leverage SKLearn model tools to conduct hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SKLearn Regressor\n",
    "Using SKLearn models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed: 58.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel_s0': 0.0007094452596116463, 'kernel_s1': 0.032187896160191284, 'kernel_s2': 0.2663595286341815, 'skl_kernel': 'laplacian', 'skl_model__alpha': 0.0006763336535533695}\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import loguniform, uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#use loguniform to search uniformaly across orders of magnitude\n",
    "distributions = {\n",
    "        'skl_model__alpha': loguniform(1e-7, 1.0e+0),\n",
    "        'kernel_s0': loguniform(1e-7, 1.0e+1),\n",
    "        'kernel_s1': loguniform(1e-6, 1.0e+1), \n",
    "        'kernel_s2': loguniform(1e-4, 1.0e+2),\n",
    "        'skl_kernel': ['laplacian', 'rbf'],  # categorical parameter\n",
    "    }\n",
    "#create search model from base model\n",
    "skl_kt_model_search = RandomizedSearchCV(skl_kt_model, distributions,\n",
    "                                     scoring = 'neg_mean_squared_error', \n",
    "                                     cv = 5, n_jobs = 1, n_iter = 100, verbose=1)\n",
    "#fit search model\n",
    "search_results = skl_kt_model_search.fit(X_train, y_train)\n",
    "\n",
    "print(search_results.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From search, set params for base model and validate against test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error for (x,y) location estimation is   5.1 meters\n"
     ]
    }
   ],
   "source": [
    "#set params based on search\n",
    "skl_kt_model.set_params(**search_results.best_params_)\n",
    "\n",
    "#fit model using best params ()\n",
    "skl_kt_model.fit(X_train, y_train)\n",
    "\n",
    "#predict and show error\n",
    "y_pred = skl_kt_model.predict(X_test)\n",
    "mse=mean_squared_error(y_pred, y_test)\n",
    "print('Average error for (x,y) location estimation is {:5.2g} meters'.format(mse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GLMnet Regressor\n",
    "Using GLMnet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed: 39.3min\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed: 102.3min\n",
      "[Parallel(n_jobs=6)]: Done 500 out of 500 | elapsed: 115.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel_s0': 0.0003017344124394731, 'kernel_s1': 0.0015381828738127007, 'kernel_s2': 0.13428923755571717, 'lambdau': 1.1024263412692438e-07, 'skl_kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import loguniform, uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#use loguniform to search uniformally across orders of magnitude\n",
    "distributions = {\n",
    "        'lambdau': loguniform(1e-7, 1.0e+0),\n",
    "        'kernel_s0': loguniform(1e-7, 1.0e+1),\n",
    "        'kernel_s1': loguniform(1e-6, 1.0e+1), \n",
    "        'kernel_s2': loguniform(1e-4, 1.0e+2),\n",
    "        'skl_kernel': ['laplacian', 'rbf'],  # categorical parameter\n",
    "    }\n",
    "#create search model from base model\n",
    "#glmnet_model uses single cpu, so increase number of jobs \n",
    "glm_kt_model_search = RandomizedSearchCV(glm_kt_model, distributions,\n",
    "                                     scoring = 'neg_mean_squared_error', \n",
    "                                     cv = 5, n_jobs = 6, n_iter = 100, verbose=1)\n",
    "#fit search model\n",
    "search_results = glm_kt_model_search.fit(X_train, y_train)\n",
    "\n",
    "print(search_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error for (x,y) location estimation is   5.7 meters\n"
     ]
    }
   ],
   "source": [
    "#set params based on search\n",
    "glm_kt_model.set_params(**search_results.best_params_)\n",
    "\n",
    "#fit model using best params ()\n",
    "glm_kt_model.fit(X_train, y_train)\n",
    "\n",
    "#predict and show error\n",
    "y_pred = glm_kt_model.predict(X_test)\n",
    "mse=mean_squared_error(y_pred, y_test)\n",
    "print('Average error for (x,y) location estimation is {:5.2g} meters'.format(mse))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#hide\n",
    "#sklearn 0.23.1 and skopt 0.74... broken dependency between the two... wait 'til one or other is upgraded\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "opt = BayesSearchCV(\n",
    "    skl_kt_model,\n",
    "    {\n",
    "        'skl_model__alpha': (1e-8, 1e+0, 'log-uniform'),\n",
    "        'kernel_s0': (1e-6, 1e+1, 'log-uniform'),'kernel_s1': (1e-6, 1e+1, 'log-uniform'), \n",
    "        'kernel_s2':(1e-6, 1e+1, 'log-uniform'),\n",
    "        'skl_kernel': ['laplacian', 'rbf'],  # categorical parameter\n",
    "    },\n",
    "    n_iter=32, cv=3, n_jobs = 3, scoring = 'neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "opt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
